{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5683b8e7-0d05-46fd-876b-57a5d89c983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Tuple\n",
    "from time import perf_counter\n",
    "from dataclasses import dataclass\n",
    "from itertools import product\n",
    "from threading import Barrier\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import torch\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79cd495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "DTYPE = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52f104f-62ce-4685-b1b6-9434f45a7b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    def __init__(self): self.loads, self.stores = 0, 0\n",
    "    def increment(self, loads: int=0, stores: int=0):\n",
    "        self.loads += loads    # increment loads\n",
    "        self.stores += stores  # increment stores\n",
    "    def show(self): print(f\"Total reads: {self.loads} Total writes: {self.stores}\")\n",
    "\n",
    "def timeit(func: Callable):\n",
    "    def timer(*args, **kwargs):\n",
    "        st = perf_counter()\n",
    "        out = func(*args, **kwargs)\n",
    "        et = perf_counter()\n",
    "        print(f\"Time elapsed: {(et - st) * 1000:.2f} ms\")\n",
    "        return out\n",
    "    return timer\n",
    "\n",
    "def cdiv(a: int, b: int): return (a + b - 1) // b  # equivalent to math.ceil()\n",
    "\n",
    "def tidx(fidx: int, tw: int): return fidx // tw, fidx % tw            # tiledIdx from flatIdx\n",
    "def fidx(tidx0: int, tidx1: int, tw: int): return tidx0 * tw + tidx1  # flatIdx from tiledIdx\n",
    "\n",
    "@dataclass\n",
    "class dim3:\n",
    "    z: int = 1\n",
    "    y: int = 1\n",
    "    x: int = 1\n",
    "    @property\n",
    "    def size(self): return self.z * self.y * self.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecaff1e0-0059-4b01-ad3b-cac7ddccbed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def launch_cuda_kernel(gridSize: dim3, blockSize: dim3, kernel: Callable, shared_size: int=0):\n",
    "    @timeit\n",
    "    def dispatch_kernel(*kernargs):\n",
    "        for blockIdx in product(range(gridSize.z), range(gridSize.y), range(gridSize.x)):\n",
    "            shared_mem = torch.zeros(shared_size, dtype=DTYPE)\n",
    "            barrier = Barrier(blockSize.size)\n",
    "            with ThreadPoolExecutor(max_workers=blockSize.size) as e:\n",
    "                for threadIdx in product(range(blockSize.z), range(blockSize.y), range(blockSize.x)):\n",
    "                    e.submit(kernel, dim3(*blockIdx), dim3(*threadIdx), blockSize, barrier, shared_mem, *kernargs)\n",
    "    return dispatch_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddce8301-973a-478e-8c38-f54540e571b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test example\n",
    "M, K, N = 12, 24, 18\n",
    "A = torch.randn(M, K, dtype=DTYPE)\n",
    "B = torch.randn(K, N, dtype=DTYPE)\n",
    "C_ref = A @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb7521e-5f28-4f9f-b013-e5bf5faa1821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_output(C: Tensor):\n",
    "    std = torch.std(C - C_ref).item()\n",
    "    ret = \"PASSED\" if torch.allclose(C, C_ref, atol=1e-6) else f\"FAILED\"\n",
    "    return f\"{ret} {std=:.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cab088d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED std=0.0000\n"
     ]
    }
   ],
   "source": [
    "print(check_output((A.view(M, 1, K) * B.T.view(1, N, K)).sum(dim=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede18360-02b4-4ec2-b71d-3c3cf3314708",
   "metadata": {},
   "source": [
    "# Matmul Naive 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec45f063-215b-4712-b4fa-c2a03d40e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_naive1D_kernel(blockIdx: dim3, threadIdx: dim3, blockSize: dim3, barrier: Barrier, shared_mem: Tensor,\n",
    "                          buffers: Tuple[Tensor, ...], metadata: Tuple[int, ...], counter: Counter):\n",
    "    idx = (blockIdx.x * blockSize.x) + threadIdx.x\n",
    "    (C, A, B), (M, K, N) = buffers, metadata\n",
    "    m, n = tidx(idx, N)\n",
    "    if m < M and n < N:\n",
    "        acc = 0.\n",
    "        for k in range(K):\n",
    "            acc += A[fidx(m, k, K)] * B[fidx(k, n, N)]\n",
    "            counter.increment(loads=2)\n",
    "        C[idx] = acc\n",
    "        counter.increment(stores=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64999740-393e-42e2-9f25-dd43845724f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_naive1D(A: Tensor, B: Tensor):\n",
    "    (M, K), (K_, N) = A.shape, B.shape\n",
    "    assert K == K_, f\"inner dims should match, {K} != {K_}\"\n",
    "    A = A.contiguous() if not A.is_contiguous() else A\n",
    "    B = B.contiguous() if not B.is_contiguous() else B\n",
    "    C = torch.empty(M, N, dtype=DTYPE)\n",
    "\n",
    "    threads = 8\n",
    "    blockSize = dim3(x=threads)\n",
    "    gridSize = dim3(x=cdiv(M * N, blockSize.x))\n",
    "    kernel = launch_cuda_kernel(gridSize, blockSize, matmul_naive1D_kernel)\n",
    "    kernel((C.flatten(), A.flatten(), B.flatten()), (M, K, N), counter:=Counter())\n",
    "    counter.show()\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12fdd2c7-3693-4bae-b4c6-8b08b56162b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 110.04 ms\n",
      "Total reads: 10368 Total writes: 216\n",
      "PASSED std=0.0000\n"
     ]
    }
   ],
   "source": [
    "C = matmul_naive1D(A, B)\n",
    "print(check_output(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8989d087-f875-4ac7-a48a-21076ce0b1c6",
   "metadata": {},
   "source": [
    "# Matmul Naive 2D Tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dc1b533-64ab-4555-9c8c-0b643ab12114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_naive2D_kernel(blockIdx: dim3, threadIdx: dim3, blockSize: dim3, barrier: Barrier, shared_mem: Tensor,\n",
    "                          buffers: Tuple[Tensor, ...], metadata: Tuple[int, ...], counter: Counter):\n",
    "    m = (blockIdx.y * blockSize.y) + threadIdx.y\n",
    "    n = (blockIdx.x * blockSize.x) + threadIdx.x\n",
    "    (C, A, B), (M, K, N, tileWidth) = buffers, metadata\n",
    "    if m < M and n < N:\n",
    "        acc = 0.\n",
    "        for tile_k in range(cdiv(K, tileWidth)):\n",
    "            for t in range(tileWidth):\n",
    "                k = fidx(tile_k, t, tileWidth)\n",
    "                if k < K:\n",
    "                    acc += A[fidx(m, k, K)] * B[fidx(k, n, N)]\n",
    "                    counter.increment(loads=2)\n",
    "        C[fidx(m, n, N)] += acc\n",
    "        counter.increment(stores=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5d020a3-dbd3-456d-8d53-48e067426a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_naive2D(A: Tensor, B: Tensor, tileWidth: int):\n",
    "    (M, K), (K_, N) = A.shape, B.shape\n",
    "    assert K == K_, f\"inner dims should match, {K} != {K_}\"\n",
    "    A = A.contiguous() if not A.is_contiguous() else A\n",
    "    B = B.contiguous() if not B.is_contiguous() else B\n",
    "    C = torch.empty(M, N, dtype=DTYPE)\n",
    "\n",
    "    blockSize = dim3(y=tileWidth, x=tileWidth)\n",
    "    gridSize = dim3(y=cdiv(M, tileWidth), x=cdiv(N, tileWidth))\n",
    "    kernel = launch_cuda_kernel(gridSize, blockSize, matmul_naive2D_kernel)\n",
    "    kernel((C.flatten(), A.flatten(), B.flatten()), (M, K, N, tileWidth), counter:=Counter())\n",
    "    counter.show()\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81165d62-5374-4a4d-8f7a-4a23193aed58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 120.11 ms\n",
      "Total reads: 10368 Total writes: 216\n",
      "PASSED std=0.0000\n"
     ]
    }
   ],
   "source": [
    "C = matmul_naive2D(A, B, 3)\n",
    "print(check_output(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad847a-b3c6-4bc8-879a-89ed5a59713f",
   "metadata": {},
   "source": [
    "# Matmul 2D Tiled (Shared Memory Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c95319fe-3423-4cfe-b4f3-786e397291d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_tiled2D_kernel(blockIdx: dim3, threadIdx: dim3, blockSize: dim3, barrier: Barrier, shared_mem: Tensor,\n",
    "                          buffers: Tuple[Tensor, ...], metadata: Tuple[int, ...], counter: Counter, scounter: Counter):\n",
    "    m = (blockIdx.y * blockSize.y) + threadIdx.y\n",
    "    n = (blockIdx.x * blockSize.x) + threadIdx.x\n",
    "    (C, A, B), (M, K, N, tileWidth) = buffers, metadata\n",
    "    offset = tileWidth ** 2\n",
    "    if m < M and n < N:\n",
    "        acc = 0.\n",
    "        for tile_k in range(cdiv(K, tileWidth)):\n",
    "            # load tile onto shared memory\n",
    "            load_a, load_b = 0., 0.\n",
    "            if (ak := fidx(tile_k, threadIdx.x, tileWidth)) < K:\n",
    "                load_a = A[fidx(m, ak, K)]\n",
    "                counter.increment(loads=1)\n",
    "            if (bk := fidx(tile_k, threadIdx.y, tileWidth)) < K:\n",
    "                load_b = B[fidx(bk, n, N)]\n",
    "                counter.increment(loads=1)\n",
    "            shared_mem[fidx(threadIdx.y, threadIdx.x, tileWidth)] = load_a\n",
    "            shared_mem[fidx(threadIdx.y, threadIdx.x, tileWidth) + offset] = load_b\n",
    "            scounter.increment(stores=2)\n",
    "            barrier.wait()\n",
    "            # compute dot products on tile\n",
    "            for t in range(tileWidth):\n",
    "                acc += shared_mem[fidx(threadIdx.y, t, tileWidth)] * shared_mem[fidx(t, threadIdx.x, tileWidth) + offset]\n",
    "                scounter.increment(loads=2)\n",
    "            barrier.wait()\n",
    "        C[fidx(m, n, N)] += acc\n",
    "        counter.increment(stores=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "117991f0-fdf4-432c-b3da-8f060063a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_tiled2D(A: Tensor, B: Tensor, tileWidth: int):\n",
    "    (M, K), (K_, N) = A.shape, B.shape\n",
    "    assert K == K_, f\"inner dims should match, {K} != {K_}\"\n",
    "    A = A.contiguous() if not A.is_contiguous() else A\n",
    "    B = B.contiguous() if not B.is_contiguous() else B\n",
    "    C = torch.empty(M, N, dtype=DTYPE)\n",
    "\n",
    "    blockSize = dim3(y=tileWidth, x=tileWidth)\n",
    "    gridSize = dim3(y=cdiv(M, tileWidth), x=cdiv(N, tileWidth))\n",
    "    kernel = launch_cuda_kernel(gridSize, blockSize, matmul_tiled2D_kernel, 2 * tileWidth ** 2)\n",
    "    kernel((C.flatten(), A.flatten(), B.flatten()), (M, K, N, tileWidth), counter:=Counter(), scounter:=Counter())\n",
    "    counter.show()\n",
    "    scounter.show()\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09f30530-4b18-4360-b6c8-52b81ff21c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 109.05 ms\n",
      "Total reads: 3456 Total writes: 216\n",
      "Total reads: 10368 Total writes: 3456\n",
      "PASSED std=0.0000\n"
     ]
    }
   ],
   "source": [
    "C = matmul_tiled2D(A, B, 3)\n",
    "print(check_output(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a935917-0870-4c1f-a2d3-e9b43e73b907",
   "metadata": {},
   "source": [
    "# Matmul Naive 3D Tiled (for fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b763202-7a5a-49ac-a827-1849792770fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_naive3D_kernel(blockIdx: dim3, threadIdx: dim3, blockSize: dim3, barrier: Barrier, shared_mem: Tensor,\n",
    "                          buffers: Tuple[Tensor, ...], metadata: Tuple[int, ...], counter: Counter):\n",
    "    m = (blockIdx.z * blockSize.z) + threadIdx.z\n",
    "    n = (blockIdx.y * blockSize.y) + threadIdx.y\n",
    "    k = (blockIdx.x * blockSize.x) + threadIdx.x\n",
    "    (C, A, B), (M, K, N) = buffers, metadata\n",
    "    if m < M and n < N and k < K:\n",
    "        C[fidx(m, n, N)] += A[fidx(m, k, K)] * B[fidx(k, n, N)]\n",
    "        counter.increment(loads=2, stores=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21c9a76e-eebf-4e43-83bf-99902c2c6b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_naive3D(A: Tensor, B: Tensor, tileWidth: int):\n",
    "    (M, K), (K_, N) = A.shape, B.shape\n",
    "    assert K == K_, f\"inner dims should match, {K} != {K_}\"\n",
    "    A = A.contiguous() if not A.is_contiguous() else A\n",
    "    B = B.contiguous() if not B.is_contiguous() else B\n",
    "    C = torch.empty(M, N, dtype=DTYPE)\n",
    "\n",
    "    gridSize = dim3(cdiv(M, tileWidth), cdiv(N, tileWidth), cdiv(K, tileWidth))\n",
    "    blockSize = dim3(tileWidth, tileWidth, tileWidth)\n",
    "    kernel = launch_cuda_kernel(gridSize, blockSize, matmul_naive3D_kernel)\n",
    "    kernel((C.flatten(), A.flatten(), B.flatten()), (M, K, N), counter:=Counter())\n",
    "    counter.show()\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f914e7a-f68f-4122-979b-041320508b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 179.80 ms\n",
      "Total reads: 10368 Total writes: 5184\n",
      "PASSED std=0.0000\n"
     ]
    }
   ],
   "source": [
    "C = matmul_naive3D(A, B, 3)\n",
    "print(check_output(C))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
